# Outlier Detection

## General
- Goal: find objects that are considerably different from most other objects or unusual or in some way
inconsistent with other objects
- Standalone task, pre-/postprocessing
- Application: Fraud detection, Medicine, Public health, Sports, Intrusion detection, measurement errors
- Causes of anomolies:
  - Data from different “classes”, Natural variation, Data measurement errors and collection errors
- Approaches
  - Supervised: 
    - classify a new instance as anomaly or not
  - Unsupervised: 
    - assign a score to each instance that reflects the degree to which the instance is anomalous
  - Naïve approach: Look for outliers by applying one of those algorithms like DBSCAN that account aoutliers and retrieve the noise set as side product
    - Problems: 
      - optimized to find clusters rather than outliers
      - Accuracy depends on clusters
      - many abnormal data similar to each other ecognized as a cluster
- Global vs local outlier detection
  - GLobal: reference set contains all other data objects, only one normal mechanism, other outliers are also in the reference set and may falsify the results
  - local: reference contains a (small) subset of data objects, how to choose a proper reference set
  - Hybrid
- Labeling vs scoring outliers
- Modeling properties
- Model-based approaches
  - Assuming a certain kind of statistical distribution (e.g., Gaussian)
  - Outliers are points that have a low probability to be generated by the overall distribution
  - Assumption: Outliers deviate strongly from this distribution
  - Robustness: Mean and standard deviation are very sensitive to outliers
- Distance-based approaches: 
  - based on the distance(s) to its neighbor(s), anomaly if it is distant from most points andless dense neighborhood
  - easier to find a suitable proximity measure than to determine the statistical distribution
  - simple but expensive and sensitive to parameters, curse of dimensionality
  - kth nearest neighbor-based:
    - outlier score of an object is given by its distance to its k-nearest neighbor (kNN distance).
    - highly sensitive to the value of k
    - cannot handle datasets with regions of widely different densities due to the global threshold k
- Density based approaches:
  - Outliers are instances in regions of low density
  - Compare the density around a point with the density around its local neighbors
  - outlier score
  - LOF (Local Outlier Factor):
    - $reach-dist_k(p, o) = max[k-distance(o), dist(p, o)]$
    - dist(p,o) is the actual distance between p and o
    - k-distance(o) is the distance of o to its k-th nearest neighbor
    - using the inverse of the average reachability distance in the KNN of p 
      - Local reachability density (lrd) of point p: $lrd_k(p) = 1/[\frac{\sum_{o\in kNN(p)}reach-dist_k(p,o)}{|kNN(p)|}]$
      - Local outlier factor (LOF) of point p: Average ratio of lrds of neighbors of p and lrd of p
        - $LOF_k(p) = \frac{1}{|kNN(p)|}* \sum_{o\in kNN(p)}\frac{lrd_k(o)}{lrd_k(p)}$
        - LOF ≈ 1: point is in a cluster (region with homogeneous density around the point and its neighbors)
        - LOF > 1: point is an outlier
      - --> outliers are points with the largest LOF values
      - Choice of k  specifies the reference set
      - local approach (resolution depends on the user’s choice for k)
      - Outputs a scoring
  - Cluster based approaches:
    - outlier if it does not strongly belong to any cluster
    - approach: 
      - Find clusters and then assess the degree to which a point belongs to any cluster
      - if the elimination of a point results in substantial improvement of the objective function, we could classify it as an outlier
    - Proprotype-based clusters: 
      - kmeans, kmedioids