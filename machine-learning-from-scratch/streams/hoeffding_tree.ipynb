{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoeffding Tree first split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class HoeffdingTree:\n",
    "    def __init__(self, Nmin, delta, R, logfunc, verbose=True):\n",
    "        self.Nmin = Nmin\n",
    "        self.delta = delta\n",
    "        self.R = R\n",
    "        self.logfunc = logfunc\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def log_debug(self, *msg):\n",
    "        if self.verbose:\n",
    "            print(*msg)\n",
    "\n",
    "    def calc_hoeffding_bound(self, i):\n",
    "        print(f\"hb = sqrt({self.R}^2*ln(1/{self.delta})/2*{i}) = {math.sqrt((self.R ** 2 * math.log(1. / self.delta)) / (2 * i))}\")\n",
    "        return (\n",
    "            math.sqrt((self.R ** 2 * math.log(1. / self.delta)) / (2 * i))\n",
    "        )\n",
    "\n",
    "    def calc_prior_entropy(self, labels):\n",
    "        c = Counter(labels)\n",
    "        entropy = 0\n",
    "        print(f\"\\nentropy(D_{len(labels)})= -(\", end = '')\n",
    "        for label in set(labels):\n",
    "            p = c[label] / len(labels)\n",
    "            entropy += p * self.logfunc(p)\n",
    "            print(f\"{p}*{self.logfunc(p)} +\", end = '')\n",
    "        print(f\")={-entropy}\")\n",
    "        return -entropy\n",
    "\n",
    "    def calc_total_attr_entropy(self, kv, i):\n",
    "        #self.log_debug(kv.keys())\n",
    "        weighted_sum = 0\n",
    "        print(f\"Entropy({kv.keys()})= \", end = '')\n",
    "        for item in kv.keys():\n",
    "            entropy = 0\n",
    "            count = sum(kv[item].values())\n",
    "            for label_count in kv[item].values():\n",
    "                p = label_count / count\n",
    "                entropy += p * self.logfunc(p)\n",
    "            weighted_sum += count / i * (-entropy)\n",
    "            print(f\"{count}/{i} * -({entropy})+\", end = '')\n",
    "            #self.log_debug('entropy for', item, \": \", -entropy)\n",
    "        print(f\"={weighted_sum}\")\n",
    "        # self.log_debug('weighted_sum:', weighted_sum)\n",
    "        return weighted_sum\n",
    "\n",
    "    def fit(self, data_columns, label_column):\n",
    "        total_len = len(next(iter(data_columns.values())))\n",
    "        for i in range(1, total_len + 1):\n",
    "            if i % self.Nmin != 0:\n",
    "                continue\n",
    "\n",
    "            print(f\"n={i}\")\n",
    "            #self.log_debug(i)\n",
    "\n",
    "            infogains = []\n",
    "\n",
    "            for attr_name, col in data_columns.items():\n",
    "                kv = defaultdict(lambda: defaultdict(int))\n",
    "                for (item, label) in zip(col[:i], label_column[:i]):\n",
    "                    kv[item][label] += 1\n",
    "\n",
    "                prior_entropy = self.calc_prior_entropy(label_column[:i])\n",
    "                total_attr_entropy = self.calc_total_attr_entropy(kv, i)\n",
    "\n",
    "                infogain = prior_entropy - total_attr_entropy\n",
    "                print(f\"infogain({attr_name})={prior_entropy}-{total_attr_entropy}={infogain}\")\n",
    "                #self.log_debug(\n",
    "                #    'infogain:',\n",
    "                #    prior_entropy,\n",
    "                #    \"-\",\n",
    "                #    total_attr_entropy,\n",
    "                #    '= ',\n",
    "                #    infogain\n",
    "                #)\n",
    "                infogains.append((infogain, attr_name))\n",
    "\n",
    "            infogains = sorted(infogains)\n",
    "            print('All infogains:', infogains)\n",
    "            eps = self.calc_hoeffding_bound(i)\n",
    "            if infogains[-1][0] - infogains[-2][0] > eps:\n",
    "                print('Split on:', infogains[-1][1])\n",
    "            else:\n",
    "                print(\"Information Gain too small, no split.\")\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=2\n",
      "\n",
      "entropy(D_2)= -(0.5*-1.0 +0.5*-1.0 +)=1.0\n",
      "Entropy(dict_keys(['1-2', '2-7']))= 1/2 * -(0.0)+1/2 * -(0.0)+=0.0\n",
      "infogain(time)=1.0-0.0=1.0\n",
      "\n",
      "entropy(D_2)= -(0.5*-1.0 +0.5*-1.0 +)=1.0\n",
      "Entropy(dict_keys(['m']))= 2/2 * -(-1.0)+=1.0\n",
      "infogain(gender)=1.0-1.0=0.0\n",
      "\n",
      "entropy(D_2)= -(0.5*-1.0 +0.5*-1.0 +)=1.0\n",
      "Entropy(dict_keys(['urban', 'rural']))= 1/2 * -(0.0)+1/2 * -(0.0)+=0.0\n",
      "infogain(area)=1.0-0.0=1.0\n",
      "All infogains: [(0.0, 'gender'), (1.0, 'area'), (1.0, 'time')]\n",
      "hb = sqrt(1^2*ln(1/0.2)/2*2) = 0.6343181205897598\n",
      "Information Gain too small, no split.\n",
      "\n",
      "n=4\n",
      "\n",
      "entropy(D_4)= -(0.5*-1.0 +0.5*-1.0 +)=1.0\n",
      "Entropy(dict_keys(['1-2', '2-7', '>7']))= 2/4 * -(-1.0)+1/4 * -(0.0)+1/4 * -(0.0)+=0.5\n",
      "infogain(time)=1.0-0.5=0.5\n",
      "\n",
      "entropy(D_4)= -(0.5*-1.0 +0.5*-1.0 +)=1.0\n",
      "Entropy(dict_keys(['m', 'f']))= 2/4 * -(-1.0)+2/4 * -(-1.0)+=1.0\n",
      "infogain(gender)=1.0-1.0=0.0\n",
      "\n",
      "entropy(D_4)= -(0.5*-1.0 +0.5*-1.0 +)=1.0\n",
      "Entropy(dict_keys(['urban', 'rural']))= 1/4 * -(0.0)+3/4 * -(-0.9182958340544896)+=0.6887218755408672\n",
      "infogain(area)=1.0-0.6887218755408672=0.31127812445913283\n",
      "All infogains: [(0.0, 'gender'), (0.31127812445913283, 'area'), (0.5, 'time')]\n",
      "hb = sqrt(1^2*ln(1/0.2)/2*4) = 0.44853064449852537\n",
      "Information Gain too small, no split.\n",
      "\n",
      "n=6\n",
      "\n",
      "entropy(D_6)= -(0.3333333333333333*-1.5849625007211563 +0.6666666666666666*-0.5849625007211563 +)=0.9182958340544896\n",
      "Entropy(dict_keys(['1-2', '2-7', '>7']))= 3/6 * -(-0.9182958340544896)+1/6 * -(0.0)+2/6 * -(-1.0)+=0.792481250360578\n",
      "infogain(time)=0.9182958340544896-0.792481250360578=0.12581458369391152\n",
      "\n",
      "entropy(D_6)= -(0.3333333333333333*-1.5849625007211563 +0.6666666666666666*-0.5849625007211563 +)=0.9182958340544896\n",
      "Entropy(dict_keys(['m', 'f']))= 4/6 * -(-0.8112781244591328)+2/6 * -(-1.0)+=0.8741854163060885\n",
      "infogain(gender)=0.9182958340544896-0.8741854163060885=0.044110417748401076\n",
      "\n",
      "entropy(D_6)= -(0.3333333333333333*-1.5849625007211563 +0.6666666666666666*-0.5849625007211563 +)=0.9182958340544896\n",
      "Entropy(dict_keys(['urban', 'rural']))= 1/6 * -(0.0)+5/6 * -(-0.7219280948873623)+=0.6016067457394686\n",
      "infogain(area)=0.9182958340544896-0.6016067457394686=0.31668908831502096\n",
      "All infogains: [(0.044110417748401076, 'gender'), (0.12581458369391152, 'time'), (0.31668908831502096, 'area')]\n",
      "hb = sqrt(1^2*ln(1/0.2)/2*6) = 0.36622373767435534\n",
      "Information Gain too small, no split.\n",
      "\n",
      "n=8\n",
      "\n",
      "entropy(D_8)= -(0.5*-1.0 +0.5*-1.0 +)=1.0\n",
      "Entropy(dict_keys(['1-2', '2-7', '>7']))= 3/8 * -(-0.9182958340544896)+3/8 * -(-0.9182958340544896)+2/8 * -(-1.0)+=0.9387218755408672\n",
      "infogain(time)=1.0-0.9387218755408672=0.06127812445913283\n",
      "\n",
      "entropy(D_8)= -(0.5*-1.0 +0.5*-1.0 +)=1.0\n",
      "Entropy(dict_keys(['m', 'f']))= 5/8 * -(-0.9709505944546686)+3/8 * -(-0.9182958340544896)+=0.9512050593046015\n",
      "infogain(gender)=1.0-0.9512050593046015=0.04879494069539847\n",
      "\n",
      "entropy(D_8)= -(0.5*-1.0 +0.5*-1.0 +)=1.0\n",
      "Entropy(dict_keys(['urban', 'rural']))= 3/8 * -(0.0)+5/8 * -(-0.7219280948873623)+=0.4512050593046014\n",
      "infogain(area)=1.0-0.4512050593046014=0.5487949406953986\n",
      "All infogains: [(0.04879494069539847, 'gender'), (0.06127812445913283, 'time'), (0.5487949406953986, 'area')]\n",
      "hb = sqrt(1^2*ln(1/0.2)/2*8) = 0.3171590602948799\n",
      "Split on: area\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Nmin = 2\n",
    "delta = 0.2\n",
    "R = 1\n",
    "grace = 2\n",
    "logfunc = math.log2\n",
    "tree = HoeffdingTree(Nmin, delta, R, logfunc)\n",
    "data_columns = {\n",
    "    'time': ['1-2', '2-7', '>7', '1-2', '>7', '1-2', '2-7', '2-7'],\n",
    "    'gender': ['m', 'm', 'f', 'f', 'm', 'm', 'f', 'm'],\n",
    "    'area': ['urban', 'rural', 'rural', 'rural', 'rural', 'rural', 'urban', 'urban']\n",
    "}\n",
    "label_columns = [\n",
    "    ['low', 'high', 'low', 'high', 'high', 'high', 'low', 'low']\n",
    "]\n",
    "tree.fit(data_columns, label_columns[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7eeab5e244e6d2bb29126e5c2117da8f926f0a00ff0a13f94b66cc877e30ded6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
